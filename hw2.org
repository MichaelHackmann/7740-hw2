
#+title: Homework 2: Formal Languages, Parsing, and Semantics
#+author: Toni Kazic
#+date: Fall, 2024


# revised <2021-09-25 Sat>

#+SETUPFILE: "../../../common/preamble.org"
#+LATEX_CLASS: article
#+OPTIONS: toc:nil
#+OPTIONS: ^:nil

#+LATEX_HEADER: \usepackage{langsci-avm}
# http://ftp.math.purdue.edu/mirrors/ctan.org/macros/latex/contrib/langsci-avm/langsci-avm.pdf
# and see also
# https://userblogs.fu-berlin.de/langsci-press/2020/04/20/writing-avms-easily-in-latex-the-new-langsci-avm-package/


#+LATEX_HEADER: \newcommand{\grmr}[2]{\ensuremath{\mathrm{#1} & \,\longrightarrow\, \mathrm{#2}}}
#+LATEX_HEADER: \newcommand{\txtgrmr}[2]{\ensuremath{\mathrm{#1} \,\longrightarrow\, \mathrm{#2}}}
#+LATEX_HEADER: \newcommand{\grmrhs}[1]{\ensuremath{& \,\longrightarrow\, \mathrm{#1} }}
#+LATEX_HEADER: \newcommand{\wa}[1]{\type{\textnormal{\w{#1}}}}

# compile with pdflatex
#
# Kazic, 3.11.2020

 

* Introduction

In this homework, the syntactic and semantic rubber hits the road.  This
homework introduces the deeper structures of language, especially when
phrased formally; looks at syntax and parsing; and extends the notion of
parsing to semantics.



* Who's Who and Solution Patterns
<<whoswho>>


** Lead Person:  yellow


** Group Members

| first name last name | color                                |
|----------------------+--------------------------------------|
| Michael Hackmann     | yellow \color{yellow}\rule{5mm}{3mm} |
|                      | green \color{green}\rule{5mm}{3mm}   |
| Ethan Glass          | purple \color{violet}\rule{5mm}{3mm} |


** Three Member Solution Patterns

$i$ is the question number.

#+begin_center
#+ATTR_LaTeX: :mode inline-math :environment array
| \text{color}                         | \text{draft solution} | \text{revise solution} |
|--------------------------------------+-----------------------+------------------------|
| green \color{green}\rule{5mm}{3mm}   | i \mod 3 = 1          | i \mod 3 = 0           |
| yellow \color{yellow}\rule{5mm}{3mm} | i \mod 3 = 2          | i \mod 3 = 1           |
| purple \color{violet}\rule{5mm}{3mm} | i \mod 3 = 0          | i \mod 3 = 2           |
#+end_center


** Two Member Solution Patterns

| color                                | draft solution | revise solution |
|--------------------------------------+----------------+-----------------|
| green \color{green}\rule{5mm}{3mm}   | odds           | evens           |
| yellow \color{yellow}\rule{5mm}{3mm} | evens          | odds            |




* General Instructions


   + /Fill out the group members table and follow the solution patterns/ in
     Section [[whoswho]].

   + /If the question is unclear, tell me your interpretation of it as part
     of your answer./  Feel free to ask about the questions in class or on
     the Slack channel (use =@channel= as others will probably be puzzled
     too). 

   + /For questions using corpora, use the corpus of the lead person./

   + /Put your draft answers right after each question using a *complete,
     functional* =org= mode code or example block./ Make sure your code
     block is complete and functional by testing it in your copy of this
     homework file.

   + /Each group member reviews the others' draft solutions and you revise them together/.

   + /Discuss each other's draft and reviews, finalizing the answers./

   + /Show all your work: code, results, and analysis./  Does your code
     work in this file and produce *exactly* the results you show? 

   + /Post the completed file to Canvas no later than noon on the Tuesday
     indicated/ in the [[../syllabus.org::schedule][schedule in the syllabus]], naming your file with each
     person's first name (no spaces in the file name, and don't forget the
     =.org= extension!).  Only one person should submit the final file.


* Hints


** Make sure the structure of the grammar can be parsed by the parser.

For example, a recursive descent parser cannot terminate the parse of a
left-recursive grammar.



** Use re-entrancy if you need it.

=NLTK= has some notation for this.




* Questions

# added directions on proving <2023-10-20 Fri>
# clarified that the rules are from separate grammars <2023-12-11 Mon>
1. [@1] <<prod-rules>> Remember those silly tags from [[file:./hw1.org::silly-tags][hw1.org]]?  Let
#
#
\begin{align}
N &= \{ \textrm{FOO,BAR,EGO,NEED,ADS,DUCK,MANSE} \} \ \text{and} \nonumber \\
T &= \{ \w{dog, black, racing, was, squirrel, tree, burrow, ground hog, bushes, towards,
hunting, back, wee} \}  \nonumber
\end{align}
#
For each of the following production rules, state from which class of
language they come and /show why/ by derivation from the language
definitions (that is, write the proof and describe it).
   + rule 1 :: $\txtgrmr{FOO}{EGO \ NEED \ DUCK}$
   + rule 2 :: $\txtgrmr{FOO \ DUCK}{EGO \ NEED \ DUCK}$ 
   + rule 3 :: $\txtgrmr{FOO}{EGO \ \w{dog} \ DUCK}$  
   + rule 4 :: $\txtgrmr{FOO \ \w{ground hog}}{EGO \ \w{dog} \ DUCK \ \w{squirrel}}$  
   + rule 5 :: $\txtgrmr{FOO}{\w{black} \ \w{dog} \ DUCK}$  
#
Each of the rules is abstracted from a different grammar!

Language definitions:

Type 0: Recursively-Enumerable - α -> β, where where α and β are strings of terminals
and non-terminals, and α is non-empty.

Type 1: Context-Sensitive - αAβ -> αγβ, where A is a non-terminal, α, β are
any strings of terminals and non-terminals, and γ is a non-empty string.
Importantly, the length of the left-hand side should not exceed the length
of the right-hand side.

Type 2: Context-Free - A -> γ, where A is a single non terminal and γ is
any string of terminals and non-terminals.

Type 3:  A -> aB or A -> aB, where A and B are non-terminals, and a is a
terminal. These rules must produce either a terminal symbol followed by a
non-terminal or just a terminal. 

+ rule 1 is context-free, because A is a single non terminal (FOO) while
  γ, the string of terminals and non-terminals, is EGO\NEED\DUCK.

+ rule 2 is context-sensitive, because A represents FOO, α represents
  DUCK, β represents a terminal, and γ represents the string EGO \ NEED.
   
+ rule 3 is context-free, since the lefthand side is a single non-terminal
  (FOO) and the right is a combo of terminals (\wdog) and non-terminals
  (EGO DUCK).
   
+ rule 4 is context-sensitive, because the left side containts two
  elements, and the right hand side meets the constraints. Crucially, the
  left-hand side does not exceed the length of the right.
   
+ rule 5 is context-free, becauset the left-hand side is a single
  non-terminal while the right is a string of terminals and non-terminals. 


2. [@2] <<which-recursn>> Consider the following grammar.
#+BEGIN_EXAMPLE
N = {A,B,C,D}
T = {foo,bar}
S = {C}
P = {C -> A B
     B -> A D
     B -> A
     D -> A A
     A -> T
     }
#+END_EXAMPLE
Is the grammar left-, right-, neither-, or both-recursive?  Why?

+ I believe the grammar is neither left or right recursive. A grammar is left recursive
  if a non terminal appears on the far left side of its production.
  Right recursion appears on the far right of its production. In the case of this problem
  none of the non terminals, A,B,C, or D reappear on the lefthand and righthand
  sides. Therefore, there is no recursive outcome. 


3. [@3] <<manual-parse>> By hand, generate a construct for each unique
   length of output using the grammar of question [[which-recursn]] and show
   them and their derivation as an =org= table:

| sentence        | rule sequence and comments                                        |
|-----------------+-------------------------------------------------------------------|
| foo bar         | C → A B → T B → T A → foo B → foo A D → foo bar                   |
| foo foo bar     | C → A B → T B → T D → foo D → foo A A → foo foo bar               |
| bar foo         | C → A B → T B → T A → bar B → bar A → bar foo                     |
| foo foo foo bar | C → A B → T B → T D → foo D → foo A A → foo A A → foo foo foo bar |



# clarified they are not to write more complex productn rules, 
# that all words are to be filtered at once, and that no trivial
# regexes are to be used.
#
# <2023-12-11 Mon>
4. [@4] <<regex>> For the terminals in question [[prod-rules]], write the
   minimum number of Python *regular expressions* (/not production rules
   from context-free or greater grammars!/) to distinguish among them /when
   the entire group of words is presented/ (not one-by-one!).  Do not use
   trivial regexes that match one and only one word.  Use conditionals and
   order the regexs into a tree until all terminals are recognized without
   ambiguities.  Carry your tree out until each terminal has a regular
   expression that places it in the leaves.  Include a sketch of your tree
   if you think it will help!

   Start
   |
   |---^EGO
   |    |---NEED -> rule 1/2
   |    |    |___DUCK$ -> rule 1/2
   |    |---DOG -> rule 3/4
   |    |    |___squirrel$ -> rule 4
   |    |    |___DUCK$ -> rule 3
   |    |
   |___^black
        |___dog DUCK$ -> rule 5


As you can see, this tree identifies all the terminals by using their regular expressions to
distinguish them. Each regex designes to match a pattern in the input strings.
Because all of the strings start with either EGO or black, those begin the tree branches. From
there they all branch off either to NEED or to DOG, and in the case of
"black" it could branch off to "dog DUCK". So by following the branches of
the tree based off the string in question, you will ifnd out what rule of
the prod rules it conforms to. The actual regex's are in the below python
code of question 5. 


5. [@5] <<regex-imp>> Now implement your regular expression tree in
   question [[regex]] and show the code and results.

#+begin_src python :results output
  import re

  # define regex patterns for each rule
  patterns = {
      "Rule 1/2": r'^EGO NEED DUCK$',       # matches both Rule 1 and Rule 2
      "Rule 3": r'^EGO dog DUCK$',           # matches Rule 3
      "Rule 4": r'^EGO dog DUCK squirrel$',  # matches Rule 4
      "Rule 5": r'^black dog DUCK$',         # matches Rule 5
  }

  # function to match input against the regex tree
  def match_rule(sequence):
      for rule, pattern in patterns.items():
	  if re.match(pattern, sequence):
	      return rule
      return "No match"

  # test cases
  test_sequences = [
      "EGO NEED DUCK",         # rule 1/2
      "EGO dog DUCK",          # rule 3
      "EGO dog DUCK squirrel", # rule 4
      "black dog DUCK",        # rule 5
      "EGO NEED DUCK"          # rule 1/2
  ]

  # running the matcher and showing results
  results = {seq: match_rule(seq) for seq in test_sequences}

  # display results
  for seq, result in results.items():
      print(f"Sequence: '{seq}' -> {result}")

#+end_src

#+results:
: Sequence: 'EGO NEED DUCK' -> Rule 1/2
: Sequence: 'EGO dog DUCK' -> Rule 3
: Sequence: 'EGO dog DUCK squirrel' -> Rule 4
: Sequence: 'black dog DUCK' -> Rule 5


6.  [@6] <<first-gram>> Write a grammar that captures the following sentences:
#
   + sentence 1 :: ``The cheerful black dog slept quietly by the chair.''
   + sentence 2 :: ``A sleepy yellow dog stretched his back.''
   + sentence 3 :: ``Somebody downstairs made the coffee.''
#
Put the phrases generated by each rule from these sentences alongside the
rules, again as an =org= table (this example is *JUST to illustrate format,
it is not correct!*):

RULE 1: S (sentence) -> NP VP
RULE 2: NP (noun phrase) -> D A | D A A N | N | D N
RULE 3: VP (verb phrase) -> V NP | V AV PP
RULE 4: PP (prep phrase) -> P NP
RULE 5: D (determiner) -> "the" | "The" | "A" | "Somebody" | "Some" | "His"
RULE 6: A (adjective) -> "cheerful" | "sleepy" | "yellow" | "black" | "downstairs"
RULE 7: N (noun) -> "dog" | "chair" | "back" | "coffee"
RULE 8: V (verb) -> "slept" | "stretched" | "made"
RULE 9: AV (adverb) -> "quietly" 
RULE 9: P (prep) -> "by"
#

| Rule                | Phrase                                                                                                                        |
|---------------------+-------------------------------------------------------------------------------------------------------------------------------|
| S → NP VP           | (The cheerful black dog slept quietly by the chair)                                                                            |
| S → NP VP           | (A sleepy yellow dog stretched his back)                                                                                       |
| S → NP VP           | (Somebody downstairs made the coffee)                                                                                         |
| NP → D A N          | (The cheerful black dog)                                                                                                      |
| NP → D A A N        | (A sleepy yellow dog)                                                                                                         |
| VP → V NP           | (stretched his back)                                                                                                          |
| VP → V AV PP        | (slept quietly by the chair)                                                                                                   |
| PP → P NP           | (by the chair)                                                                                                                |
| D                   | (the) (The) (A) (Somebody) (Some) (His)                                                                                       |
| A                   | (cheerful) (sleepy) (yellow) (black) (downstairs)                                                                            |
| N                   | (dog) (chair) (back) (coffee)                                                                                                |
| V                   | (slept) (stretched) (made)                                                                                                     |
| P                   | (by)                                                                                                                                  |   |

# added pretty printing, so much easier to follow
#
# Kazic, 15.12.2023


7. [@7] <<recur-desc-parser>> Now implement the grammar of question
   [[first-gram]] as a recursive descent parser.  Parse each sentence, showing
   the results as a prettily printed tree, and compare them.  What do you
   observe?

#+begin_src python :results output
import nltk
from nltk import CFG

# define the grammar
grammar = CFG.fromstring("""
S -> NP VP
NP -> D A | D A A N | D N
VP -> V NP | V AV P NP
PP -> P NP
D -> 'the' | 'The' | 'A' | 'Somebody' | 'Some' | 'his'
A -> 'cheerful' | 'sleepy' | 'yellow' | 'black' | 'downstairs'
N -> 'dog' | 'chair' | 'back' | 'coffee'
V -> 'slept' | 'stretched' | 'made'
AV -> 'quietly'
P -> 'by'
""")

sentences = [
    "The cheerful black dog slept quietly by the chair",
    "A sleepy yellow dog stretched his back",
    "Somebody downstairs made the coffee"
  ]

for sentence in sentences:
    tokens = sentence.split()
    print("Tokens:", tokens)
    parser = nltk.RecursiveDescentParser(grammar)
    for tree in parser.parse(tokens):
        print(tree)
        tree.pretty_print()

#+end_src

#+results:
#+begin_example
Tokens: ['The', 'cheerful', 'black', 'dog', 'slept', 'quietly', 'by', 'the', 'chair']
(S
  (NP (D The) (A cheerful) (A black) (N dog))
  (VP (V slept) (AV quietly) (P by) (NP (D the) (N chair))))
                         S                            
        _________________|____________                 
       |                              VP              
       |                  ____________|_______         
       NP                |      |     |       NP      
  _____|____________     |      |     |    ___|____    
 D     A       A    N    V      AV    P   D        N  
 |     |       |    |    |      |     |   |        |   
The cheerful black dog slept quietly  by the     chair

Tokens: ['A', 'sleepy', 'yellow', 'dog', 'stretched', 'his', 'back']
(S
  (NP (D A) (A sleepy) (A yellow) (N dog))
  (VP (V stretched) (NP (D his) (N back))))
                   S                        
       ____________|_____________            
      |                          VP         
      |                    ______|___        
      NP                  |          NP     
  ____|____________       |       ___|___    
 D    A      A     N      V      D       N  
 |    |      |     |      |      |       |   
 A  sleepy yellow dog stretched his     back

Tokens: ['Somebody', 'downstairs', 'made', 'the', 'coffee']
(S
  (NP (D Somebody) (A downstairs))
  (VP (V made) (NP (D the) (N coffee))))
                         S                 
           ______________|____              
          |                   VP           
          |               ____|___          
          NP             |        NP       
    ______|______        |     ___|____     
   D             A       V    D        N   
   |             |       |    |        |    
Somebody     downstairs made the     coffee

#+end_example


The parser is successfuly generating trees for all of the sentences, and it identifies noun phrases, verb phrases,
and other componentes like prepositional phrases. It finds adverbs and determiners as well. By expanding the grammer to include all
of the words, the parser can handle a big variety of sentence structure. I had to include 'his' to make sure it covered that case.
Before I did, it raised an error stating that some vocabulary was missing and needed to be identified. The parser seems to be
flexible and can generate trees from different types of sentence formats. That was a big takeaway that I had. All of the sentences
start with a similar structue of S -> NP and VP. They start with a noun phrase followed by a verb phrase. The cheerful black dog
had to account for miltiple adjectives modifying the noun. The sentence with someone making cofee only takes one adjective. This shows
the grammer can handle both simple and complex noun phrases. The verb phrases are very different. quietly, and stretched, made, are all
different ways to use a verb. The parser was able to pick up those different structures. 


8. <<chart-parser>> Following on, implement the grammar of question
   [[first-gram]] as a chart parser.  Parse each sentence, showing the results,
   and compare these chart parsing results to your results in question
   [[recur-desc-parser]].  What do you observe?

#+begin_src python :results output
  import nltk
  from nltk import CFG

  # define the grammar
  grammar = CFG.fromstring("""
    S -> NP VP
    NP -> D A | D A A N | D N
    VP -> V NP | V AV P NP
    PP -> P NP
    D -> 'the' | 'The' | 'A' | 'Somebody' | 'Some' | 'his'
    A -> 'cheerful' | 'sleepy' | 'yellow' | 'black' | 'downstairs'
    N -> 'dog' | 'chair' | 'back' | 'coffee'
    V -> 'slept' | 'stretched' | 'made'
    AV -> 'quietly'
    P -> 'by'
  """)

  # create a chart parser
  chart_parser = nltk.ChartParser(grammar)

  # sentences to parse
  sentences = [
    "The cheerful black dog slept quietly by the chair",
    "A sleepy yellow dog stretched his back",
    "Somebody downstairs made the coffee"
  ]

  # parsing and displaying trees
  for sentence in sentences:
    print(f"Parsing sentence: '{sentence}'")
    tokens = sentence.split()
    parse_trees = list(chart_parser.parse(tokens))  # Get all possible parse trees
    for tree in parse_trees:
      print(tree)
      tree.pretty_print()
    if not parse_trees:
      print("No parse trees found.")
    print()


#+end_src

#+results:
#+begin_example
Parsing sentence: 'The cheerful black dog slept quietly by the chair'
(S
  (NP (D The) (A cheerful) (A black) (N dog))
  (VP (V slept) (AV quietly) (P by) (NP (D the) (N chair))))
                         S                            
        _________________|____________                 
       |                              VP              
       |                  ____________|_______         
       NP                |      |     |       NP      
  _____|____________     |      |     |    ___|____    
 D     A       A    N    V      AV    P   D        N  
 |     |       |    |    |      |     |   |        |   
The cheerful black dog slept quietly  by the     chair


Parsing sentence: 'A sleepy yellow dog stretched his back'
(S
  (NP (D A) (A sleepy) (A yellow) (N dog))
  (VP (V stretched) (NP (D his) (N back))))
                   S                        
       ____________|_____________            
      |                          VP         
      |                    ______|___        
      NP                  |          NP     
  ____|____________       |       ___|___    
 D    A      A     N      V      D       N  
 |    |      |     |      |      |       |   
 A  sleepy yellow dog stretched his     back


Parsing sentence: 'Somebody downstairs made the coffee'
(S
  (NP (D Somebody) (A downstairs))
  (VP (V made) (NP (D the) (N coffee))))
                         S                 
           ______________|____              
          |                   VP           
          |               ____|___          
          NP             |        NP       
    ______|______        |     ___|____     
   D             A       V    D        N   
   |             |       |    |        |    
Somebody     downstairs made the     coffee


#+end_example

From the charts themselves, I actually don't notice any difference.
They appear to be the same, and I don't know if that's because of pretty
print formatting or because the outputs of the parse are truly
identical. It could be the way the two parsing methods are programmed in
NLTK, but here they come out identical. 

9. <<clock>> Extend your grammar for the sentences in question
   [[recur-desc-parser]]  so that it can parse sentences 4--6 below.  Time the
   implementation's performance for each sentence, doing this 1000 times
   for each sentence for better estimates, and put the results  in an =org= table.
   + sentence 4 :: ``We had a long walk to the park and Vinny played with
     three other dogs.''
   + sentence 5 :: ``It was sunny today but might not be tomorrow.''
   + sentence 6 :: ``There are 49 angels dancing on the head of this pin.''

#+begin_src python :results output
import time
import nltk
from nltk import CFG
import re

def punctuation_fix(sentence):
    return re.findall(r"\w+|[^\w\s]", sentence) #https://www.codecademy.com/resources/docs/python/regex/findall

grammar = CFG.fromstring("""
    S -> NP VP | S CONJ S
    NP -> D A N | D A A N | D N | N | D N PP | NUM N | N PP | D N PP | N PP
    VP -> V NP | V AV P NP | V NP PP | V ADVP
    PP -> P NP
    ADVP -> AV | AV ADVP
    D -> 'The' | 'the' | 'A' | 'a' | 'Somebody' | 'Some' | 'his' | 'We' | 'It' | 'There' | 'this'
    A -> 'cheerful' | 'sleepy' | 'yellow' | 'black' | 'downstairs' | 'long' | 'sunny' | 'other'
    N -> 'dog' | 'dogs' | 'Vinny' | 'chair' | 'back' | 'coffee' | 'walk' | 'park' | 'angels' | 'head' | 'pin'
    V -> 'slept' | 'stretched' | 'made' | 'had' | 'played' | 'was' | 'might' | 'be' | 'are' | 'dancing'
    AV -> 'quietly' | 'today' | 'tomorrow' | 'not'
    P -> 'by' | 'with' | 'to' | 'on' | 'of'
    NUM -> '49' | 'three'
    CONJ -> 'and' | 'but'
    PUNCT -> '.' | ',' | '!'
""")

# Sentences to parse
sentences = [
    "We had a long walk to the park and Vinny played with three other dogs.",
    "It was sunny today but might not be tomorrow.",
    "There are 49 angels dancing on the head of this pin."
]

def parse_sentence(sentence, parser, iterations=1000):
    tokens = punctuation_fix(sentence)
    time_begin = time.time()
    for _ in range(iterations):
        list(parser.parse(tokens))  
    time_end = time.time()
    return time_end - time_begin

chart_parser = nltk.ChartParser(grammar)

findings = []
for sentence in sentences:
    time_taken = parse_sentence(sentence, chart_parser)
    findings.append((sentence, time_taken))

for sentence, time_taken in findings:
    print(f"Sentence: '{sentence}' took {time_taken:.4f} seconds to parse 1000 times.")

#+end_src

#+results:
: Sentence: 'We had a long walk to the park and Vinny played with three other dogs.' took 1.0871 seconds to parse 1000 times.
: Sentence: 'It was sunny today but might not be tomorrow.' took 0.6154 seconds to parse 1000 times.
: Sentence: 'There are 49 angels dancing on the head of this pin.' took 1.0496 seconds to parse 1000 times.


| Sentence                                                               | Time (seconds) |
|------------------------------------------------------------------------+----------------|
| We had a long walk to the park and Vinny played with three other dogs. |         1.3391 |
| It was sunny today but might not be tomorrow.                          |         0.7393 |
| There are 49 angels dancing on the head of this pin.                   |         1.2394 |





10. <<avm-graph>> Consider this attribute-value matrix:
#
#+begin_export latex
\begin{center}
\avm{
[ CAT  & s \\
  HEAD & [ AGR   & \1 [ NUM & sg \\
                        PER & 3 ] \\
           SUBJ  & [ AGR \1 ] ] ] \\
}.
\end{center}
#+end_export
#
Draw the corresponding directed acyclic graph, ideally in Python.  (A hand-drawn figure is fine:
just photograph it and include the image below, as is done in [[file:../notes.org][notes.org]].)


                 |---SUBJ--sg-->NUM
PER <--3---AGR<--|
                 |---Head<------CAT




11. [@11] <<basic-fea-struc>> Now extend your grammar from question [[clock]] to include features
    relevant to subject-verb agreement, using =nltk.FeatStruct()= from
    chapter nine, so that you can parse sentences 1--9.  Using
    =cp.parse()=, print and study the parse trees for each sentence.  Do
    you agree with them?  Why or why not?

   + sentence 7 :: ``The black dogs are playing with the elf toy.''
   + sentence 8 :: ``The yellow dog slept in my pajamas.''
   + sentence 9 :: ``We will take two long rides in the country next
     week.''

#+begin_src python :results output
import nltk
from nltk import FeatureChartParser
from nltk import CFG
import re
from nltk.grammar import FeatureGrammar
import matplotlib.pyplot as plt
from nltk.draw.tree import TreeView
from nltk.tree import Tree

def punctuation_fix(sentence):
  return re.findall(r"\w+|[^\w\s]", sentence)

grammar = nltk.grammar.FeatureGrammar.fromstring("""
    S[NUM=?n, PER=?p] -> NP[NUM=?n, PER=?p] VP[NUM=?n, PER=?p]
                      | S[NUM=?n, PER=?p] CONJ S[NUM=?n, PER=?p]

    NP[NUM=sg, PER=3] -> D A N[NUM=sg, PER=3]
    NP[NUM=pl, PER=3] -> D A N[NUM=pl, PER=3]
    NP[NUM=sg, PER=1] -> 'I'
    NP[NUM=pl, PER=1] -> 'We'
    NP[NUM=pl, PER=3] -> D N[NUM=pl, PER=3]

    VP[NUM=sg, PER=3] -> V[NUM=sg, PER=3] NP | V[NUM=sg, PER=3] PP | V[NUM=sg, PER=3] AV P NP
    VP[NUM=pl, PER=3] -> V[NUM=pl, PER=3] NP | V[NUM=pl, PER=3] PP | V[NUM=pl, PER=3] AV P NP
    VP[NUM=pl, PER=1] -> 'will' V[NUM=pl, PER=3] NP

    PP -> P NP

    D -> 'The' | 'the' | 'A' | 'a' | 'Somebody' | 'Some' | 'his' | 'We' | 'It' | 'There' | 'this' | 'my'
    A -> 'black' | 'cheerful' | 'sleepy' | 'yellow' | 'long' | 'sunny' | 'other'
    N[NUM=sg, PER=3] -> 'dog' | 'toy' | 'elf' | 'ride' | 'country' | 'week' | 'pajamas' | 'child'
    N[NUM=pl, PER=3] -> 'dogs' | 'toys' | 'angels'

    V[NUM=sg, PER=3] -> 'sleeps' | 'plays' | 'sees' | 'is' | 'was' | 'might' | 'has' | 'barks'
    V[NUM=pl, PER=3] -> 'are' | 'play' | 'take' | 'dancing' | 'sees'

    AV -> 'quietly' | 'today' | 'tomorrow' | 'not'
    P -> 'by' | 'with' | 'to' | 'on' | 'of' | 'in' | 'next'
    CONJ -> 'and' | 'but'
""")


sentences = [
  "The cheerful black dog slept quietly by the chair",
  "A sleepy yellow dog stretched his back",
  "Somebody downstairs made the coffee",
  "We had a long walk to the park and Vinny played with three other dogs",
  "It was sunny today but might not be tomorrow",
  "There are 49 angels dancing on the head of this pin",
  "The black dogs are playing with the elf toy",
  "The yellow dog slept in my pajamas",
  "We will take two long rides in the country next week",
]
cp = FeatureChartParser(grammar)
def punctuation_fix(sentence):
    return re.findall(r"\w+|[^\w\s]", sentence)


for sentence in sentences:
  print(f"Parsing: {sentence}")
  parsed_tree = cp.parse(sentence.split())
  print(parsed_tree)
  for tree in parsed_tree:
    print(tree)
    tree.draw()  
#+end_src

#+results:
#+begin_example
Parsing: The cheerful black dog slept quietly by the chair
<generator object FeatureChart.parses at 0x111e77e20>
(S[]
  (NP[NUM='sg']
    (D[NUM='sg'] The)
    (A[] cheerful)
    (A[] black)
    (N[NUM='sg'] dog))
  (VP[NUM='sg']
    (V[NUM='sg'] slept)
    (AV[] quietly)
    (P[] by)
    (NP[NUM='sg'] (D[NUM='sg'] the) (N[NUM='sg'] chair))))
Parsing: A sleepy yellow dog stretched his back
<generator object FeatureChart.parses at 0x111e77c40>
(S[]
  (NP[NUM='sg']
    (D[NUM='sg'] A)
    (A[] sleepy)
    (A[] yellow)
    (N[NUM='sg'] dog))
  (VP[NUM='sg']
    (V[NUM='sg'] stretched)
    (NP[NUM='sg'] (D[NUM='sg'] his) (N[NUM='sg'] back))))
Parsing: Somebody downstairs made the coffee
<generator object FeatureChart.parses at 0x111e77d30>
Parsing: We had a long walk to the park and Vinny played with three other dogs
<generator object FeatureChart.parses at 0x111e77f10>
Parsing: It was sunny today but might not be tomorrow
<generator object FeatureChart.parses at 0x111e77d30>
Parsing: There are 49 angels dancing on the head of this pin
<generator object FeatureChart.parses at 0x111e77c40>
Parsing: The black dogs are playing with the elf toy
<generator object FeatureChart.parses at 0x111e77d30>
Parsing: The yellow dog slept in my pajamas
<generator object FeatureChart.parses at 0x111e77c40>
Parsing: We will take two long rides in the country next week
<generator object FeatureChart.parses at 0x111e77d30>
#+end_example



12. [@12] <<fopc>> [[../../reading/blk_2nd_ed.pdf][Chapter 10 of BLK]] and [[http://www.nltk.org/howto/semantics.html][the semantics howto]] march one through the basics
   of applying the FOPC and the \lambda calculus to reifying the semantics of
   context-free sentences.  One of the practical difficulties in this
   approach is ensuring that the implementation of the universe of
   discourse (they call it the /domain of discourse/, same thing) actually
   covers the intended universe.

   To see this, let's use their =sem2.fcfg= grammar to parse the following
   sentences syntactically and semantically, and output the reification of
   the sentences into the FOPC and the \lambda calculus.  

   (HINT: be sure to 
   #+begin_src python :results output
   from nltk.sem import *
   #+end_src
   so you get all the parts and save yourself frustration!)  

   For each of the following sentences, parse them and print the sentence,
   its parse, and its semantics; and then explain the results you get and
   exactly how you would fix the problems encountered.

      + Suzie sees Noosa.
      + Fido barks.
      + Tess barks.

#+begin_src python :results output

  from nltk.sem import *
  from nltk import load_parser
  from nltk.grammar import FeatureGrammar
  from nltk.parse.featurechart import FeatureChartParser

  file_path = "/Users/michaelhackmann/Desktop/7740-hw2/sem2.fcfg"

  parser = load_parser(file_path, trace=0)

  sentences = [
    "Suzie sees Noosa",
    "Fido barks",
    "Tess barks"
  ]

  for sentence in sentences:
    sentence_copy = sentence.split()
    print(f"Sentence: {sentence}")
    trees = list(parser.parse(sentence_copy))
    for tree in trees:
      print(tree)
      print(tree.label()['SEM'])

#+end_src

#+results:
#+begin_example
Sentence: Suzie sees Noosa
(S[SEM=<see(suzie,noosa)>]
  (NP[-LOC, NUM='sg', SEM=<\P.P(suzie)>]
    (PropN[-LOC, NUM='sg', SEM=<\P.P(suzie)>] Suzie))
  (VP[NUM='sg', SEM=<\y.see(y,noosa)>]
    (TV[NUM='sg', SEM=<\X y.X(\x.see(y,x))>, TNS='pres'] sees)
    (NP[+LOC, NUM='sg', SEM=<\P.P(noosa)>]
      (PropN[+LOC, NUM='sg', SEM=<\P.P(noosa)>] Noosa))))
see(suzie,noosa)
Sentence: Fido barks
(S[SEM=<bark(fido)>]
  (NP[-LOC, NUM='sg', SEM=<\P.P(fido)>]
    (PropN[-LOC, NUM='sg', SEM=<\P.P(fido)>] Fido))
  (VP[NUM='sg', SEM=<\x.bark(x)>]
    (IV[NUM='sg', SEM=<\x.bark(x)>, TNS='pres'] barks)))
bark(fido)
Sentence: Tess barks
(S[SEM=<bark(Tess)>]
  (NP[-LOC, NUM='sg', SEM=<\P.P(Tess)>]
    (PropN[-LOC, NUM='sg', SEM=<\P.P(Tess)>] Tess))
  (VP[NUM='sg', SEM=<\x.bark(x)>]
    (IV[NUM='sg', SEM=<\x.bark(x)>, TNS='pres'] barks)))
bark(Tess)
#+end_example

Analysis: The parse worked correctly, and the semantics are visible as
well. "Suzie sees Noosa" and "Fido Barks" came out correctly, and the
semantic breakdown see(suzie,noosa) and bark(fido) show that the domain
contains all the need stuff, or other words, the domain of discourse
contains our information. The last sentence didn't work, because the name
"Tess" wasn't in the domain. I downloaded the sem2.fcfg file on my local
machine and added it, and that fixed that problem.



* Grading Scale

This homework is worth 15 points.  The grading
scale is:

| fraction correctly reviewed and answered | points awarded |
|------------------------------------------+----------------|
| \(\ge 0.95\)                             |             15 |
| 0.90 -- 0.94                             |             14 |
| 0.85 -- 0.89                             |             13 |
| 0.80 -- 0.94                             |             12 |
| 0.75 -- 0.79                             |             11 |
| 0.70 -- 0.74                             |             10 |
| 0.65 -- 0.69                             |              9 |
| 0.60 -- 0.64                             |              8 |
| 0.55 -- 0.59                             |              7 |
| 0.50 -- 0.54                             |              6 |
| 0.45 -- 0.49                             |              5 |
| 0.40 -- 0.44                             |              4 |
| 0.35 -- 0.39                             |              3 |
| 0.30 -- 0.34                             |              2 |
| 0.25 -- 0.29                             |              1 |
| \(< 0.25\)                               |              0 |




* Scoring


|     question | max pts | answer ok? |
|--------------+---------+------------|
|            1 |       1 |            |
|            2 |       1 |            |
|            3 |       1 |            |
|            4 |       1 |            |
|            5 |       1 |            |
|            6 |       2 |            |
|            7 |       1 |            |
|            8 |       1 |            |
|            9 |       1 |            |
|           10 |       1 |            |
|           11 |       2 |            |
|           12 |       2 |            |
|--------------+---------+------------|
|  total score |      15 |          0 |
|   percentage |         |          0 |
| total points |         |            |
#+TBLFM: @14$2=vsum(@I..@II)::@14$3=vsum(@I..@II)::@15$3=@-1/@-1$-1



